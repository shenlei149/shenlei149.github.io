## 序言
我们积累了海量信息，但是仍旧无法回答生命中最重大的问题：我们究竟是谁？我们应该追求什么？什么才是所谓美好的生活，我们又该怎样过上这样的生活？

希腊神话法厄同和魔法师学徒告诉我们：永远别去召唤自己控制不了的力量。人类之所以喜欢召唤自己控制不了的力量，问题不在于个人的心理，而在于人类在大规模合作时的一种特性。虽然人类能够建立大规模合作网络，以此获取巨大的力量，但这些网络的构建方式注定了人类对这些力量的运用常常并不明智。人类遇到的问题归根结底时个网络问题。更明确一点，是个信息问题。

天真的信息观认为有了足够多的信息，就能得到真理与真相；有了真理与真相，就能得到力量与智慧。面对收集与处理信息遇到的大多数问题，解决办法就是收集与处理更多的信息。这听起来就相当不明智。就算我们准确地分析了信息，发现了重要事实，也无法保证我们因此得到了力量之后就能够明智地加以应用。

或许，坐拥更多的信息让事情变得更好还是更糟，很快就有答案了。

《未来简史》中认为历史真正的主角一直都是信息，而不是智人。在民粹主义者眼中，信息就是一种武器。信息能够带来权力。只有权力是唯一的现实。民粹主义者除了这些偏激之处，正确之处在于对天真信息观持怀疑态度。

事实是，信息既不能说肯定能带来真理与真相，但它也不只是一种武器。

## 第一部分 人类网络
> 智人之所以成功，秘诀在于懂得运用信息，并把许多人联结起来。但很遗憾，人类在拥有这种能力的同时，常常也伴随着相信谎言、错误与幻想。

### 第一章 什么是信息
通常情况，信息是与各种人造符号（例如口语或书面语）联系在一起的。要不要把某个事物定义成信息是视角问题，任何事物都有可能是信息，但也可能不是。比如星星、百叶窗、鸽子，放到正确的情境下，就可能成为信息。天真的信息观认为只要情境是为了寻求真相，这些对象就能被定义为信息。这就将“信息”和“真相”两个概念联系起来了。

所谓“真相”代表的是能够准确呈现出现实的特定方面。真相其实并不直接等于现实，因为一则叙事无论多么贴近真相，都无法真正呈现出现实的所有方面。想要呈现出现实的另一个问题是现实总包含许多不同的观点。现实包括客观现实，不受个人信念的影响。然而现实也包括主观层面的主管现实，涵盖的是每一个人的信念和感受，在这种时候，我们并不会说这些现实是错误的。所谓的真相，一方面能够让我们专注于现实的某些方面，另一方面也不可避免让我们忽略某些东西。

从占星术的例子可以看出，各种错误、谎言、幻想与虚构故事其实也是信息。天真的信息观认为信息与真相有本质的联系，但事实不然。信息在历史上所发挥的作用，本来就不要呈现既有的现实，反而是要将各种不同的事物联系在一起，来创造全新的现实。真正定义信息的是“联结”。

如果把信息视为一种社会联结，人类历史的许多方面就更能说得通，除了能解释占星术，也能解释一些更重要的事物，比如《圣经》为何在历史上如此成功。在人类起源、迁徙与疫情方面，《圣经》的描述相当糟糕，但在联结数十亿人并创立了犹太教和基督教方面，《圣经》则是非常有效。信息都会联结形成网络，而这才是信息真正的基本定义特征。

智人之所以成功，秘诀在于懂得运用信息，并把许多人联结起来。

### 第二章 故事：无限的联结
我们智人能够统治世界，并不是因为我们有多聪明，而是因为唯有人类能够进行灵活的大规模合作。智人在有了故事之后，出现了新的联结：人与故事的联结。“品牌”就是特定类型的故事。品牌打造也应用于个人，此时，联结只是关于那个人的故事，而故事与真人之间常常有着巨大的鸿沟。人类所知的各种联结中，家庭可以说是最牢固的一种。故事在陌生人之间建立信任的方式之一，就是让人类去想象彼此是自己的家人。

在人类开始讲故事之前，现实只有两个层次：主管现实与客观现实。故事创造了第三个层次的现实：存在于实体间的现实。主管现实只存在于个人的心智之中，但主体间的现实（法律、国家、神祗、企业、货币等）则存在于许多心智形成的联结里。国家，就是一种存在于主体之间的实体。在我们问某个国家是否存在时，是在提出一个关于主体间的问题。对大规模人类网络发展最重要的就是那么能够创造出主体间现实的故事。

故事产出了大规模的人类网络，这些网络反过来又彻底改变了世界的力量平衡。事实上，大规模人类群体之间的身份认同本身就是由故事定义的，所以这些群体之间的所有关系，当然也都是由故事塑造的。

让人们团结起来，相较于真相，虚构的故事在两个方面更有优势。第一，虚构的故事要多简单就可以多简单，但真相往往很复杂，因为它要呈现现实，而现实是复杂的。第二，真相常常令人痛苦不安，如果我们想让它别那么令人痛苦，变得比较讨人喜欢，真相也就不再是真相了。虚构的故事可塑性更高。如果要追求科学进步，就必须毫不妥协，坚持真理和真相，而且这也是一种让人钦佩的精神实践，但讲到政治，坚持真理与真相绝非制胜之道。仅仅讲一个虚构的故事，并不是说谎，大大方方承认自己就是在创造一个新的主体间现实，而不是在呈现某个既有的客观现实，那么讲述一个虚构的故事就不是说谎。人类的政治制度都是以虚拟故事为基础的，只是有些人承认这一点，而有些人不承认罢了。

与天真的信息观不同，复杂的信息观是
```
信息------->真相--->智慧
  |          |
  |          |
  v          v
 秩序------>力量
```
如果某个人类网络把秩序看得比真相更重要，它可能掌控着无比强大的力量，却会不明智地使用力量。信息技术变得更快、更有效率，不一定会让世界变得更美好，相反这只会让我们更迫切地需要在真相与秩序之间达到平衡。

### 第三章 文件：纸老虎也会咬人
故事这种信息技术也有局限性。人脑能够记住民族诗歌与神话，但复杂的国家税收与管理系统想要运作，就必须靠一种独特的、非生物的信息技术——书面文件。

插一句，这里作者和我有一个相同的观点：真正的爱国，是要好好纳税。

书面文件创造出了一个新的现实，不管这个现实是真还是假。文件让人有新的方法创造主体间的现实。所有权是一种通过交换信息创造出来的主体间现实，不知过信息的形式现在是书面文件或电子文档，而不是人类的言语和行为。社会、经济和政治关系所依赖的文件都创造了现实，而不只是呈现现实。

信息太多，人类创造出了一种全新而极度棘手的问题：信息检索。在大型组织里，人类就是用官僚制度来解决资料检索的问题，进而创造出更庞大也更强大的信息网络的。

这套秩序解决检索问题的方法，也正是把整个世界分成许多不同的抽屉，再判断该把哪些文件放进哪个抽屉。执着于把现实分成一个个固定的抽屉，也会让官僚的目光变得狭隘，无视自己的行为可能带来更广泛的影响。官僚制度的扭曲，除了影响政府和企业，科学研究也无法幸免。

官僚制度是为了维持秩序，要是没了秩序，任何大规模的人际网络都将难以维系。

神话故事常常让人欢喜赞叹，而官僚制度则让人摇头怀疑。不论是有益还是有害的官僚制度，都有一个关键特征，就是人类很难搞清楚它们在干些什么。随着文件称为许多社会链条的重要节点，文件开始承载着无与伦比的权力，能掌握这些文件背后的神秘逻辑，就能称为新的权威人物。《第二十二条军规》中掌握了最大权力的角色可以说是任职于收发室的前一等兵温特格林，他在这个权力基地可以决定要让哪些邮件发出去，哪些邮件又会消失。

所有威力强大的信息网络都是可好可坏的，这取决于它们的设计与使用方式。

### 第四章 错误：绝对正确是一种幻想
自我修正机制想要发挥作用，就必须取得合法性。如果人一定会犯错，那么自我修正机制不也会犯错吗？人类幻想存在某种超人类、绝不犯错的机制。以前这种机制叫宗教，未来这种机制可能是人工智能。就历史而言，宗教最重要的功能是为社会秩序提供超人类的合法性。

每个宗教的核心都离不开一个幻想，即与一个超人类的、绝对可靠的智能体相联结。

使用书这项信息技术，就能确保不同的人在不同的时间、地点访问同一个数据库。从公元前 1000 年开始，书就成了一项重要的宗教技术。问题来了：谁来决定在圣书中放进哪些内容？人编纂了《圣经》。

假定确定了内容，仍旧有很多问题。第一个问题是文本的复制，如何保证人不会犯下错误而更改这书宗教经典的内容呢？拉比为宗教经典的抄写制定了严格的规定。即便如此，还是有很多抄写错误。第二个问题是解读经文的方式。诸多不同的解读和诠释，造成的影响甚至大于宗教经典本身。这使新的拉比制度权威大增。当拉比们达成共识，觉得机会再次成熟，以后就可以摆脱这些会犯错的凡人机制了。循环开始了。人类梦想着能够通过宗教经典这种技术来避开会犯错的凡人机制，但这永远只是个无法实现的梦想。

基督教认为对耶和华的话语权有最终解释权的人应该是耶稣基督而不是拉比。但是很快遇到了与拉比们类似的问题，于是乎《新约》诞生了。虽然众人将宗教经典视为绝对的权威来源，但在编纂的过程中，真正的权力其实在编纂机构手中。想把所有权利都交给一项绝对正确的超人类技术，反而早就了一个全新且极其强大的人类机构——教会。

印刷术并非科学革命最根本的原因。在那些认为印刷术带来科学的人眼中，生产及传播更多信息就是在将大众引向真理与真相。事实上，印刷术能够迅速传播的除了科学事实，还有宗教幻想、虚假新闻和各种阴谋论。

能够真正推动科学革命发展的既不是印刷术，也不是完全自由的信息市场，而是能够解决“人会犯错”这个问题的创新方法。

从印刷术与猎巫的历史可以看出，自由的信息市场并不一定能让人发现并改正自己的错误，因为在这样的信息市场里，暴行的优先级可能比真理与真相更高。人类是因为发现了自己的无知，才推动了科学革命。科学革命从一开始就不相信有绝对正确这种事，其打造的信息网络也认为错误本就不可避免。科学鼓励怀疑与创新，而不鼓励遵循与顺从。

自我修正机制愿意接受自己的错误。这里的自我修正指的是实体会用这些机制来修正自己的错误。科学期刊发表了一篇论文，修正了过去谋篇论文的错误，这个就是自我修正了。自我修正在自然界无所不在，比如学会走路，其他身体机能——血压、血糖、体温可以在一定范围波动。天主教会有过道歉，难能可贵，不过历任教皇都很小心地不把责任放在《圣经》与教会这些机构制度上，而是让个别教会人士承担责任。自我修正是是对外部压力和内部反省的回应。对于天主教这样的机构而言，即使真的自我修正，也不会承认。改变教会教义的第一条法则，就是永远不能承认改变了教会教义。否认自我修正，虽然不会阻止自我修正的发生，但确实不利于修正的程度与速度。

在出现重大错误与罪行的时候，科学机构制度愿意承认是制度本身出了问题。因此，科学的发展速度随之加快。

科学的自我修正机制之所以格外强大，是因为科学机构制度不仅愿意承认自己的错误与无知，还会积极揭露这些错误与无知。

自我修正机制虽然有利于追求真相，却会让维持秩序的成本大大提高。自我修正机制太过强大，往往会产生怀疑、分歧、冲突与列哼，并破坏社会大团结的神话。如何维持真相与秩序之间的平衡，始终是信息网络的历史中很重要的一部分。为了秩序而牺牲真理与真相需要付出代价；反之，为了真相与真理而牺牲秩序，代价同样不低。

### 第五章 抉择：民主与极权制度简史
这里将民主与独裁视为两种相对的信息网络类型。独裁信息网络的第一个特征在于高度集中，第二个特征在于人们会认定中央是绝对正确的，所以并不欢迎对中央政策的任何挑战。总而言之，独裁政体是一种集中式的信息网络，而且缺乏强大的自我修正机制。而民主政体则是一个分布式的信息网络，并且拥有强大的自我修正机制。民主政体的另一个重要特征在于相信人人都可能犯错，因此虽然会赋予中央政府一些重大决策权，但同时也会保留一些能够挑战中央权威的强大机制。当然，有些时候所有人必须保持一致，而不允许存在多样性。

把民主定义为拥有强大自我修正机制的分布式信息网络，就会与民主等于选举这种常见的误解形成鲜明对比。民主制度是指对于中央权力有明确限制的制度。强人破坏民主最常用的方法之一，就是攻击民主的自我修正机制，常常是从法院与媒体下手。民主这个制度要保障所有人都能拥有某些自由，就算其他人占了多数也无法剥夺。第一类就是人权（生命权、工作权、隐私权、宗教信仰自由等），第二类就是公民权（投票权、新闻自由、集会自由等）。

人权与公民权都是存在与主体间的约定，是人类的发明而非发现，是出于历史的偶然而不是出于普遍的理性。选举所确定的只是多数人想要什么，而不是真相是什么。当然，学术机构、媒体与司法制度也可能出现贪腐、偏见或错误。但是如果要求它们服务于政府，很可能只会让事情变得更糟。真想找出真相，最好用以下两种办法：第一，学术机构、媒体、司法制度都具有自我修正机制，能用来对抗腐败，修正偏见，揭露错误。第二，由于有许多不同的独立机构会通过各种方式来寻求真相，这些机构也就能够彼此制衡、修正。

“简单”是独裁信息网络的特征，因为这种网络就是由中央决定一切，其他人只需默默服务。这种民粹主义信条的一个基本要素就是没有把人民看作一群拥有不同观点与利益、活生生的人，而认为人民是一个神秘而统一的实体，只有单一的意志，也就是“人民的意志”。要判断某人是不是民粹主义者，就看是否声称只有自己能够代表人民，而其他不同意他的观点的人都是为虚假意识所迷惑或者根本不是真正的人民。民粹主义还有另一种破坏民主的方式，在声称只有他们能代表人民之后，开始声称人民不但是政治权力唯一合法来源，更是所有权力的唯一合法来源。总而言之，这种观点把人性看得极为卑劣，但是还是有两点让其具有吸引力。第一，它把所有互动都简化成了阶级斗争，于是现实变得似乎不再复杂，所有战争、经济危机和自然灾害等等事件也变得好懂多了。不管发生任何事情（即使是全球疫情）都是因为精英分子在追求权力。第二，民粹主义有时候确实是对的。

民主与独裁的区别不是非黑即白，而是如同一道连续的光谱。

极权主义总觉得自己绝对正确、无懈可击，也希望能够彻底掌握人民的生活。在专制信息网络中，统治者的意志虽然不受法律限制，但还是会受到许多技术限制。而在极权网络中，许多技术限制根本就不存在。

现代科技除了能让人类有可能实现大规模民主，也让人类有可能实现大规模极权。

极权政权有一个关键原则：无论人民在哪里见面、交换信息，都必须受到政权的密切监控。

现代极权机构制度与前现代教会有巨大差异。第一，现代极权制度会设置许多互相重叠的监视机制，以便彼此制衡、维持秩序。而天主教会就是一个独立机构，与国家机构常常出现冲突而非合作。第二，中世纪教会常常属于坚守传统的组织，抗拒改变，而现代极权政党则往往是期许革命的组织，要求改变。还有一点是前现代教会之所以不会称为极权制度的工具，是因为他们和前现代组织一样受到了当时技术的限制。随着广播出现，教皇也成了在全球权势数一数二的角色。

民主与极权这两种全然不同的信息网络类型，各有优点和缺点。集中式极权网络的最大优势在于秩序一目了然，迅速做出决定，并且不带情绪地坚定执行。特别是遇到战争或疫情这样的紧急情况，集中式网络能够比分布式网络动作更快、走得更远。缺点也很明显。由于规定了信息只能通过官方渠道流动，一旦官方渠道被封锁，信息就没有其他传播方式。官方渠道被封锁的一个常见原因是出现了某些坏消息，而下属感到担心害怕，不想让上级知道。另一个常见原因是希望维持秩序。当然，民主管家的领导人也不喜欢坏消息，但在分布式民主信息网络中，即使官方通信线路被封锁，信息也能通过其他渠道流动。

正如不能说印刷术带来了猎物行动或科学革命，也不能说无线电技术造就了极权体系或民主体系。科学技术创造的只是新机会，但要追求把我哪些机会，依然由人做出选择。到了 21 世纪，政治上的主要分歧可能并不是民主政治与极权政治之间的分歧，而是人类与非人类个体之间。可能出现一道新的硅幕，居于两侧的可能不是民主政治与极权政治，而是一侧是所有人类，另一侧是我们无法理解的算法霸主。

## 第二部分 非生物网络
> 在能够自己追求目标、自行做出决策的计算机出现之后，人类信息网络的基本结构就变了。

### 第六章 新成员：与众不同的计算机
计算机本质上就是一台机器，但有可能做到两件了不起的事情：一是它可以自己做决定，二是它可以创造新的想法。在缅甸出现的对罗兴亚人的暴力问题上，为什么算法决定助长的是愤怒而不是慈悲呢？就算是对脸书批评最严厉的人，也不会觉得脸书的人类管理者就是想煽动大屠杀。但是为了追求用户参与度，算法就做出了一个致命决定：传播愤怒。到了 21 世纪 20 年代初，算法已经能够自行制造假新闻和阴谋论。

把智能与意识混为一谈，于是让许多人觉得某个实体要是没有意识，就不能拥有智能。然而，智能与意识其实是两回事。智能是实现目标的能力。细菌、植物不具备任何意识，但它们能表现出智能，甚至人体大部分决策都无需意识的参与。虽然计算机没有意识，但还是能做出决策。因此计算机究竟会不会发展出意识，就眼前的问题而言其实并不重要。只要有智能，能够做出决策就足够了。能够自己追求目标、自行做出决策的计算机出现之后，人类信息网络的基本结构也就改变了。

在计算机兴起之前，不论是教会还是国家，这些信息网络里的每个链条，人类都是不可或缺的环节。但是在全新的、以计算机为基础的网络中，计算机本身就是网络成员之一，甚至有计算机对计算机的连接，中间完全不需要经过人类。

在人工智能崛起之前，所有塑造人类社会的故事都源自人类的想象。但到了 2024 年，非人类智能已经有能力轻松编写出有同样语言与政治复杂性的文章，并发布到网上。人工智能不但能够编写新的“经文”，海恩那个自行筛选、自行解读，无需任何人类的参与。计算机掌握了语言之后，还能更进一步。通过与人类交谈互动，计算机可以与人类建立亲密关系，并用这种亲密的力量来影响人类，这是一种“虚假的亲密关系”。即使没有创造“虚假的亲密关系”，计算机在掌握语言之后也会对人类的观点和世界观产生重大影响：把这种计算机顾问给的建议当作是一站式的神谕。以前信息茧房还有其他人编造，不愿的将来，计算机设计的成分会越来越高。

这个信息网络还会有越来越多的另外两种新型链条。第一种是计算机与人类的连接，计算机在人类之间充当中介，有时甚至会控制人类。第二种目前已经开始出现的计算机与计算机的链接，计算机能够彼此自行互动，人类被排除在这些链接之外，就连理解其中发生了什么都很困难。

这个网络将会创造出全新的政治与个人现实。前面说过信息并不等于真理与真相，而信息革命也并不会揭露事实真相。信息革命创造出新的政治结构、经济模式与文化规范。信息革命的重要性要远胜过往，它可能会以前所未有的规模创造出前所未有的现实。

我们做的决定，最后也必须由我们负责。但是带领计算机革命的企业往往会把责任推给用户和选民，或者推给政治人物或监管机构，他们用的话术就是“我们只是一个平台。”这样的论点不是太天真，而是太虚伪。

现在以信息换信息的交易已经无处不在。数十亿人与科技巨头进行大量交易，我们从巨头那里获取信息，代价也是信息。既然只用信息就能交换到他们想要的东西，为什么还需要美元呢？这对税收有深远的影响。如果税收制度仍然只能对货币征税，很快就会跟不上时代。

民主制度担心会崛起新的数字独裁，独裁制度担心会出现不知该如何控制的行为者，而所有人应该担心未来将会失去隐私，数据殖民主义即将开始。关于这些威胁的讨论才刚刚开始，但科技的发展却远远快于政策的发展。

### 第七章 永不停歇：网络永远持续运行
在过去那个由人类来监控人类的世界，基本上享有隐私是件天经地义的事。但如果到了一个由计算机来监控人类的世界，人类就有可能在史上首次完全失去隐私。不论是好是坏，为了打击犯罪、打击异己或对抗真实或想象中的威胁，政府都会在全国不满互联网或离线的监控网络，安装间谍软件、监控摄像头、人脸与语音识别软件，以及庞大的数据库。政府监控网络还会在知情或不知情的状况下，固定收集全民的各种生物特征数据。人的任何身体活动都会留下一连串数据的痕迹。

如同各种强大的科技，这些系统可以用来行善，也能用来作恶。运用这种技术虽然理论上值得称赞，但显然可能引发在隐私与政府越权方面的忧虑。这些技术可以用于识别暴乱分子、营救失踪儿童和禁止足球流氓，极权者也可以用于迫害和平示威者或是严格要求所有人遵守同一套僵化的规定。

监控还有许多不同的形式。比如爱吃醋的配偶，员工受到雇主的监控。还有一种点对点监控体系，由个人不断相互监视，比如国际旅游评论网猫途鹰。这种点对点的监控改变了私人与公共空间的边界，抹杀了私密感。

计算机形成的网络永远运行，正逼着人类走向一种新的生活方式：永远连线，永远受到监控。

### 第八章 可能出错：谬误百出的网络
在量子力学中，光是观察亚原子粒子，就会让这些粒子的行为发生改变。观察人类的行为也是如此：我们的观察工具越强大，可能造成的影响越大。

我们已经到了一个历史转折点：当下历史的重大进程，有一部分由非人类智能的决定推动的。正因如此，计算机网络的易错性才变得如此危险。计算机犯错原本不算什么，但当计算机成了历史推动者时，这些错误就可能带来灾难。人类时非常复杂的生物，良好社会秩序会培养人类的美德，同时减少人类的消极倾向。然而社交媒体算法只把人看成矿井，想要“开采”更多的注意力。随着各种不良影响的日益显现，科技巨头不也不断被警告要注意这些影响，但因为它们坚持天真的信息观，所以未能进行干预。如果人们可以完全自由地表达自己，真理常常会败下阵来。

一致性问题：只要人类给计算机一个特定的目标，计算机就会竭尽全力，以各种不同方式实现这个目标。但由于计算机的运作与人类大不相同，很可能所用的方法完全出乎人类的意料，造成未曾遇见的危险后果，而与人类最初确立的目标完全不一致。

在计算机网络的背景下，一致性问题的危险特别高，原因之一就是这个网络的权力可能远远高于过去任何人类官僚机构。第二个原因是因为都是非生物实体，所以它们采用的策略可能是所有人类从未想到的，自然无力预见并阻止。第三个原因在于计算机与人类实在差异太大，所以就算我们不小心给出了与人类利益不一致的目标，计算机也不太会有所警觉或要求说明。所有行动都必须向某个更高的目标看齐，保持一致。

内群体与外群体只是存在于主体间的概念，其定义常常源自一些虚构的故事。于是，原本一心追求普世理性规则的义务论，最后往往称为地方虚构故事的俘虏。一台遵守康德的逻辑，而且想活下去的计算机，并没有理由反对“杀死生物很可行”这样的普世规则，反正这条规则并不会危机非生物的计算机。应该告诉计算机保护所有“能够感受到痛苦的实体”。

一致性问题本质上就是个神话问题。金钱、神祗这种存在于主体间的现实除了能影响人的思想，也能影响物理现实；同理，存在于计算机间的现实同样能影响存在于计算机之外的现实。宝可梦和谷歌排名这样的计算机间现实，就很想人类创造的主体间的现实，例如圣殿的庄严感和城市的神圣性，人民争抢宝可梦和争抢耶路撒冷没啥区别。人类在几万年间主宰着地球，是因为只是人类有能力创造并维持各种主体间实体（比如企业、货币、神祗、国家），再通过这些实体来组织大规模合作。现在，计算机也可能具备类似的能力。

从税收、医疗保健到安全和司法，随着计算机在越来越多的官僚体系中取代人类，也就越来越可能形成另一套神话谎言，并以前所未有的效率硬套在我们头上。计算机给人贴上假标签，而且让人绝对撕不下来的效率，很有可能高得吓人。

许多研究都显示计算机同样有根深蒂固的偏见。算法可以从训练的数据中学到种族歧视和厌女偏见。算法很可能学会偏见，甚至将其放大，比如学习什么是稳定的员工，可能学会任人唯亲，因为这些人录取容易且不会离职或被裁。摆脱算法偏见的难度或许不低于摆脱人类的偏见。问题是哪里才能找到完全没有偏见的数据集？

计算机觉得自己找到了某些关于人类的真相，事实上却只是把一套秩序硬套在人类头上。社交媒体算法以为自己发现了人类喜欢感到愤慨，其实是算法让人产生与接收到了更多的愤慨情绪。这种偏见一方面是由于计算机低估了人类的能力，另一方面也是因为计算机低估了自己影响人类的能力。

人类在几千年前就梦想着找到一种无懈可击的信息技术，以保护我们免受人类贪腐堕落与错误的影响。有人觉得计算机就是答案，计算机像是一部神圣的宗教经典，这部经典不但能与我们对话，还能自我诠释，完全无需任何人类机构介入。这种想法将是一场极度危险的赌博。向人类网络一样，计算机网络可能无法在真相与秩序之间找到适当的平衡。如何探究与纠正呢？一种可能的防范方式是训练计算机时要注意到自己是否出错。不论算法是否意识到自己可能出错，我们都不该在这个过程中完全排除人类的参与。

新的计算机网络不一定是好是坏。我们能确定的是人类将很难理解这种网络，而且这种网络是会犯错的。因此，人类建立的机构除了要能够发现各种常见的人类弱点（比如贪婪和仇恨），还得有能力觉察从未见过的错误。这个难题无法用技术来解决，它是一个政治上的挑战。

## 第三部分 计算机政治学
> 我们所有人在未来几年所做的选择，将决定召唤这种非人类智能究竟是个致命错误，还是会让生命的演化翻开一个充满希望的新篇章。

### 第九章 民主制度：我们还能对话吗？
人类经历了很多可怕的教训才学会如何管理蒸汽动力与电报技术，现在还得付出多少代价，才能学会管理生物工程与人工智能呢？比起 20 世纪的科技，21 世纪的科技更具威力，能够造成更大的破坏。因此能够犯错的空间更小了。

民主政体能够也应该遵循如下基本原则。几百年前甚至几千年前，我们就知道这些原则，现在只是把这些原则再应用于计算机时代的新现实。第一个民主原则是为善。如果计算机网络要收集关于我的信息，必须是来帮助我的，而不是操纵我的。如果科技巨头目前的商业模式无法负起受托人的职责，政府可以要求它们回归相对传统的商业模式，也就是让用户以金钱而不是数据来支付服务费用。或者某些非常重要的数字服务，应该让所有人都能免费使用。第二个原则是去中心化。民主社会绝不该允许所有信息集中在一处，不管是政府还是民间企业。第三个原则是相互性。如果民主制度打算加强对个人的监控，就必须同时加强对政府与企业的监控。第四个民主原则是监控系统必须永远保留让人改变与休息的空间。民主社会如果采用强大的监控技术，都得小心避免走向太过刻板或弹性过大的极端。人生在世，要学会在“提升自己”与“接受自己”之间找到平衡。算法不应该像一个暴君要求我们少吃多动、改变喜好、调整习惯，否则就降低我们的社会信用评分。

新信息技术对民主造成的威胁，不止监控这一件事。第二个威胁是自动化破坏就业市场稳定，进而破坏民主。有些我们几百年来奉若至宝，觉得属于人类独有的技能，说不定很容易自动化；但是有些我们常常气若敝屣的技能，自动化的难度却很高。比起洗碗的自动化，下棋的自动化要简单很多，相比医生，护士的工作其实更难自动化。第二个常见错误假设是唯有人类拥有创造力，所以只要是需要创造力的工作就很难自动化。第三个错误的假设是计算机无法取代人类那些需要情绪智能（又称情商）的工作，比如心理理疗师或教师。正因为人工智能没有自己的情绪，所以它能比人类更懂得如何辨识情绪，总有一天它能把人类的感受拿捏得极为细致。未来的就业将极不稳定，在未来几十年，旧工作会消失，新工作会出现，但新工作很快也会改变并消失。

人类在 21 世纪最重要的生存技能可能就是灵活性，而民主政体比极权政体更为灵猴。在未来几十年，经济的动荡程度可能比 20 世纪 30 年代初期的大规模失业或女性进入就业市场带来的动荡更大。因此，民主制度的灵活性、质疑旧神话的意愿，以及强大的自我修正机制，都是至关重要的资产。

计算机正在做出越来越多关于我们的约定，有些只关乎日常小事，但有些关乎生命大事，比如量刑、上大学、找工作、福利、贷款等等。随着社会把越来越多的决定权交给计算机，民主的自我修正机制、透明度与问责制都会受到挑战。AlphaGo 与李世石下棋的中，神来一笔的第 37 手成为了人工智能的象征。第一，让人看到人工智能本质上的非人类与难以理解。第二展示了人工智能的高深莫测。这种非人类的、难以理解的智能会让民主受到迫害。如果越来越多关于人民生活的决定都是黑盒子里完成的，选民无法理解，也无法挑战那些决定，民主就会停摆。人类不善于同时权衡诸多不同因素，算法能够将更多的因素纳入考量。对于一项参考了这么多因素做出的决定，人类的心智要怎么加以评估分析？或许最重要的是，我们无法理解算法是怎么从数据里找出规律模式并加以如何分配的。不管研发了什么技术，人类都必须维持官僚机构制度，有人类负责审核算法，决定要不要盖下许可章。这些机构制度将结合人类与计算机的力量，确保新的算法系统安全公正。

新的计算机网络对民主制度的最后一个威胁不是形成数字极权，而是促成数字无政府状态。我们担心可能造成无政府状态，是因为人工智能除了会让新的人类群体加入公开辩论，还在历史上第一次让民主必须应对各种来自非人类的杂音。另一个担心的趋势在于内容，全新的生成式人工智能能输出内容。最后，算法不但成了对话里的成员，而且开始操纵对话。如果操纵人心的机器人程序与我们无力监督的算法开始主导公共对话，民主辩论制度就可能在我们最需要它的时候彻底崩溃。公民无法分辨自己辩论的对象是人类还是机器，而且就连最基本的讨论规则或事实都无法达成共识。无政府状态下的信息网络，既不能找出真相，也无法维持秩序，注定长久不了。

法律不但应该禁止深度伪造特定的真实人物，同时还应该禁止非人类行为冒充人类，就像禁止伪造货币一样。许多对话都欢迎各种数字工具加入，但前提是不要假冒为人。还有就是要禁止算法在无人监督的情况下对关键的公共辩论进行筛选和管理。

### 第十章 极权主义：所有力量归于算法？
机器学习算法的兴起，可能正是独裁者们已经等了太久的好消息。人工智能似乎也倾向于将信息与决策都集中在一处。马太效应，信息自然而然的更集中，形成垄断。所有信息与权力都集中在一个地方，曾经是 20 世纪极权政权的致命弱点，但到了人工智能时代却可能称为决定性的优势。

虽然人工智能有许多方面有利于中央集权，但专制与极权政权在人工智能面前也并非无往不利。首先，独裁政权并没有控制非生物行为者的经验。虽然人类工程师可以尽最大努力打造出向政府看齐的人工智能，但鉴于人工智能具有自我学习与改变的能力，难保哪天走向政府不乐见的方向。最后，政府如果采取了某项极为失败的政策，后来又改变心意，常常就会把失败推到别人头上掩饰自己的过错。但要怎样才能训练聊天机器人程序，要它赶快忘记那些今天被批得一文不值但在短短一年前还是国家官方立场的政策？

政权还可能遇上更大的危险：算法并不是仅仅批评这些政权，而是直接控制了这些政权。独裁者最不乐见的就是创造出比自己更强大或自己控制不了的力量。

独裁者如果想要摆脱尾大不掉的下属，可以选择信任理论上绝对正确的技术，但这种时候，它们就可能称为信息技术的傀儡。如果独裁者想要建立一个人类机构来监督人工智能，就得小心这个机构对独裁者的权力造成限制。

### 第十一章 硅幕：全球帝国还是全球分裂？
目前，计算机还没有强大到足以完全摆脱人类的控制，或是独立摧毁人类的文明。只要人类团结一心，就能打造出适当的机构制度，用来控制人工智能，找出并修正算法的错误。但遗憾的是，人类从未真正团结一心，总是有些坏人在作乱，而好人也不见得都能达成共识。于是人工智能兴起之所以会对人类构成生存威胁，并不是因为计算机真的抱有什么恶意，而是因为人类自己的缺陷问题。

要理解新的计算机政治，绝不能只谈个别社会该如何应对人工智能，而必须考虑人工智能会怎样影响全球不同社会之间的关系。计算机对目前的国际体系还有两大挑战。第一，由于计算机让信息与权力更容易集中于单一中央枢纽，人类可能进入一个新的帝国时代。第二，一道新的硅幕可能让人类分裂，使之分属于敌对的数字帝国。

国家完全依赖各种数字基础建设与人工智能系统，而国家对它们又无法进行有效控制，这可能会导致一种新型的数据殖民主义，即通过控制数据来统治遥远的殖民地。数据殖民主义与过去的殖民类似。人工智能产业的原材料是数据，新的帝国经济从全世界收集原始数据，流向帝国中心，研发最先进的技术，生产出无与伦比的算法，再把生产出的算法出口到数据殖民地。新信息经济的本质，可能会让帝国中心与被剥削的殖民地之间形成比过往更严重的不平衡。人工智能与自动化对于较贫困的发展中国家会是一场特别的挑战。结果可能是在某些地区出现大量新的就业机会与巨大财富，而世界许多其他地区则成为一片经济废墟。

想要跨越硅幕取得信息正变得越来越困难。硅幕两侧所用的数字网络与代码也渐行渐远，各自有不同的规范，也有着不同的目的。由于数字代码会影响人类的行为，而人类的行为又会反过来塑造数字代码，于是硅幕的两侧就这样走上完全不同的路径，不仅在科技上越来越不同，在文化价值观、社会规范与政治结构方面的差异也越来越大。

人类社会分类成一个又一个的信息茧，不但会造成经济对抗与国际紧张局势，还会发展出各种截然不同的文化、意识形态与身份认同。下面提出许多大胆的猜测。一种可能的影响深远的发展就是不同的数字茧开始对人类身份这种最基本的问题有了不同的想法。到 21 世纪，计算机网络可能会让身心问题变得更严重，从而引发各种重大的个人、意识形态与政治冲突。一个越来越重要的问题是我们应该自由选择自己喜欢的虚拟身份还是应该受到生物身体的限制？哪一个更基本呢？

虽然目前人工智能竞赛是由中、美两国领先，但参赛者可不只有这两国。于是，世界或许不是落入两个大国之手，而是被十几个国家瓜分。人工智能时代冲突升级的危险更大，因为网络战与核战有着本质上的不同。第一，网络武器能做到的远比核弹更多。第二，也是二者的关键差异，即可预测性，“保证同归于尽”原则可能不再确定。

现在全球合作之所以如此困难，一大主因在于一种错误的观念，即认为合作就得先消除所有文化、社会与政治差异。全球合作与爱国主义并不互斥。全球主义并不意味着就要建立全球帝国、放弃对国家的忠诚或是开放边界无限制地接受移民。全球合作代表的是没那么激进的两件事。第一，遵守某些全球规则。第二，有时候（但不是永远）有必要将全人类的长期利益置于少数人的短期利益至上。

对人工智能的监管需要前所未有的信任与自律，原因有：第一，想掩饰非法的人工智能实验室，要比掩饰非法的核反应堆容易多了；第二，比起核弹，人工智能有更多的军民两用用途。战争的激烈程度并不取决于永不改变的人性，而取决于不断改变的科技、经济与文化因素。只要这些因素出现变化，战争也会跟着变化。战争逐渐减少，并不是因为什么神圣的奇迹或自然法则彻底转变，而是因为人类改变了自己的法律、神话与制度，并且做出了更好的决定。遗憾的是，既然这种变化源自人类的选择，也就意味着趋势有可能逆转。

作者无法预测人们在未来会做出怎样的决定，但身为历史学者，作者确实相信有改变的可能。历史唯一不变的，就是改变。

## 结语
新信息技术的发明总能促成重大的历史变革，因为信息最重要的作用就是编制新的网络，而不是呈现既有现实。由于人工智能是人类第一次能够自行做出决策并产生想法的科技，因此这项发明很有可能比过去电报、印刷机甚至文字的发明都更重要。随着人工智能的能力权威不断增加，甚至称为一本能够自圆其说的宗教经典，现在工程师所做的决定就可能深深影响后世的发展。

对于信息网络与信息革命不要采取两种常见但错误的态度。第一，我们必须小心太过天真乐观的信息观。我们并没有理由期待人工智能一定能够打破过去的模式，并更为偏向真理。第二，我们也应该避免过犹不及，变得太过犬儒主义而采取一种过于愤世嫉俗的观点。民粹主义常说权力是唯一的现实，认为一切人类互动只是权力斗争，信息也只是用来打倒敌人的武器。但现实从来不是如此，也没有理由认为人工智能将会造成这样的情形。

如果我们真有那么聪明，为什么还会走上自我毁灭的道路？本书认为，问题并不在于人类的本性，而在于人类的信息网络。由于人类的信息网络重秩序而轻真理，因此往往带来大量的力量，却没带来多少智慧。当然，力量本身不是什么坏事。如果使用得当，力量也能用来行善。因此，随着网络越来越强大，自我修正机制也会越来越必要。然而，如果硅基时代的超级大国完全没有或只有薄弱的自我修正机制，那么它危机的可能是整个人类物种与无数其他生命形式的生存。

令人遗憾的是，虽然自我修正机制会深深左右人类的长期福祉，政客却有着削弱这些机制的动机。地球演化了 40 亿年，才出现了一个拥有高度智能的猿类文明。如果人类灭亡，需要再演化上亿年，才会出现拥有高度智能的老鼠文明，这种事迟早发生。宇宙就是这么有耐心。

好消息是只要我们放下自满、不要绝望，就能够打造有制衡机制的信息网络，不让权力失控。这是一项困难且平凡的工作：为各种机构制度打造强大的自我修正机制。这种智慧的源头，甚至比人类历史还久远，是来自最基本的有机生命的基础。
